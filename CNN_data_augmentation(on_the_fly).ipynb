{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__oOBujfmsZw",
        "outputId": "21653fb6-8ec9-4e07-d6c0-73ed75014a5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.6.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (1.17.2)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.10.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (25.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.45)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from optuna) (6.0.3)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (4.15.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.12/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.3)\n",
            "Downloading optuna-4.6.0-py3-none-any.whl (404 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m404.7/404.7 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.10.1-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, optuna\n",
            "Successfully installed colorlog-6.10.1 optuna-4.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. The \"On-the-Fly\" Augmentation Workflow (Summary)\n",
        "\n",
        "**The Concept:**\n",
        "Instead of creating a giant dataset of modified images *before* training, we modify the images *during* training, right before the model sees them.\n",
        "\n",
        "**The Step-by-Step Flow:**\n",
        "\n",
        "1.  **Storage:** Your memory (RAM) holds only the **original** clean images (e.g., 50,000 images).\n",
        "2.  **The Trigger (Epoch Loop):** The training loop starts. The `DataLoader` requests a batch of 100 images.\n",
        "3.  **The Fetch & Transform (CPU Work):**\n",
        "    * The CPU grabs 100 original images from memory.\n",
        "    * The CPU applies the `transform` pipeline to these 100 images.\n",
        "    * *Crucial:* Since the transforms are **random**, the CPU might flip Image #5 this time, but rotate it next time.\n",
        "4.  **The Handoff (GPU Work):** The CPU hands these 100 *newly modified* tensors to the GPU.\n",
        "5.  **Training:** The GPU calculates predictions, loss, and updates weights. The modified images are then **discarded**.\n",
        "6.  **The Repeat:** In the next Epoch, when the code loops back to Image #5, the CPU grabs the *original* again, applies *fresh* random transforms, and the model sees a version it has likely never seen before.\n",
        "\n",
        "**The Math:**\n",
        "* **Memory Used:** $1 \\times \\text{Dataset Size}$\n",
        "* **Images Seen by Model:** $\\text{Epochs} \\times \\text{Dataset Size}$\n",
        "\n",
        "---\n",
        "\n",
        "### 2. Why is this the Industry Standard?\n",
        "\n",
        "You asked why \"on-the-fly\" is preferred over creating a static, larger dataset (e.g., saving 5 flipped versions of every image to your hard drive). There are three massive reasons:\n",
        "\n",
        "#### A. Infinite Variety (Generalization)\n",
        "If you pre-generate 5 versions of an image, your model only ever sees those 5 specific versions. It might memorize that \"Rotated 10 degrees = Dog\".\n",
        "\n",
        "With on-the-fly augmentation, the model might see:\n",
        "* **Epoch 1:** Rotated 2°\n",
        "* **Epoch 2:** Rotated -5° + Flipped\n",
        "* **Epoch 3:** Rotated 8°\n",
        "\n",
        "**Result:** The model learns the *concept* of a \"Dog\" regardless of orientation, rather than memorizing specific pixel patterns. This drastically reduces **overfitting**.\n",
        "\n",
        "#### B. Storage Constraints (The 1TB Problem)\n",
        "Real-world datasets are huge.\n",
        "* **ImageNet** is ~150 GB.\n",
        "* If you wanted to pre-augment it 10 times, you would need **1.5 TB** of disk space.\n",
        "* If you use on-the-fly augmentation, you need **0 extra bytes** of disk space.\n",
        "\n",
        "#### C. Free computational time (CPU/GPU Pipelining)\n",
        "You might think, *\"Doesn't transforming images slow down training?\"*\n",
        "\n",
        "**Actually, no.** PyTorch uses \"Multiprocessing\" (the `num_workers` argument in DataLoader).\n",
        "1.  While the **GPU** is busy sweating over the heavy matrix multiplication for *Batch 1*...\n",
        "2.  The **CPU** is effectively idle. So, it uses that \"free time\" to prepare and augment *Batch 2*.\n",
        "3.  By the time the GPU finishes Batch 1, Batch 2 is already waiting. This makes augmentation \"computationally free.\""
      ],
      "metadata": {
        "id": "E15BKEkijxI5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import optuna\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "OXu13je4mwUy"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "ydMhk8g8nUko"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tk9EPX5Qne4g",
        "outputId": "de512f43-0767-4b31-f786-ade718a1819e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "from kagglehub import KaggleDatasetAdapter\n",
        "\n",
        "file_path = \"fashion-mnist_train.csv\"\n",
        "\n",
        "df = kagglehub.load_dataset(\n",
        "  KaggleDatasetAdapter.PANDAS,\n",
        "  \"zalando-research/fashionmnist\",\n",
        "  file_path\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPdd9hhznhmC",
        "outputId": "65d223e2-19a1-4bcc-e892-c5ea83a00e9e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1182604528.py:6: DeprecationWarning: Use dataset_load() instead of load_dataset(). load_dataset() will be removed in a future version.\n",
            "  df = kagglehub.load_dataset(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'fashionmnist' dataset.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = df.iloc[:, 1:], df.iloc[:, 0]"
      ],
      "metadata": {
        "id": "zSQGZhRAognG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xtrain, xtest, ytrain, ytest = train_test_split(x, y)"
      ],
      "metadata": {
        "id": "j_J5nAFooLUX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xtrain = xtrain/255\n",
        "xtest = xtest/255"
      ],
      "metadata": {
        "id": "NrnMEUuLoneM"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "augment_pipeline = transforms.Compose(\n",
        "    [\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomRotation(10)\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "c4dBuPaediin"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "\n",
        "  def __init__(self, features, labels, transform=None):\n",
        "    # What -1 does: It tells PyTorch, \"I don't want to count exactly how many images are in this array manually. You calculate it.\"\n",
        "    self.features = torch.tensor(features, dtype=torch.float32).reshape(-1, 1, 28, 28)\n",
        "    self.labels = torch.tensor(labels, dtype=torch.long)\n",
        "    self.transform = transform\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.features)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    img, label = self.features[idx], self.labels[idx]\n",
        "\n",
        "    if self.transform:\n",
        "      img = self.transform(img)\n",
        "\n",
        "    return img, label"
      ],
      "metadata": {
        "id": "vsaQoBWQoxDf"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "traindataset = CustomDataset(xtrain.values, ytrain.values, transform=augment_pipeline)\n",
        "testdataset = CustomDataset(xtest.values, ytest.values)"
      ],
      "metadata": {
        "id": "LqEftt0fxV58"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "traindataloader = DataLoader(traindataset, batch_size=100, shuffle=True, pin_memory=True)\n",
        "testdataloader = DataLoader(testdataset, batch_size=100, shuffle=False, pin_memory=True)"
      ],
      "metadata": {
        "id": "im_tTw3Wxs-F"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class myCNN(nn.Module):\n",
        "\n",
        "  def __init__(self, input_features):\n",
        "    super().__init__()\n",
        "    self.features = nn.Sequential(\n",
        "        nn.Conv2d(input_features, 32, 3, padding='same'),\n",
        "        nn.BatchNorm2d(32),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2, 2),\n",
        "\n",
        "        nn.Conv2d(32, 64, kernel_size=3, padding='same'),\n",
        "        nn.BatchNorm2d(64),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2, 2),\n",
        "    )\n",
        "\n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(64*7*7, 128),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.4),\n",
        "\n",
        "        nn.Linear(128, 64),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.4),\n",
        "\n",
        "        nn.Linear(64, 10)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.features(x)\n",
        "    x = self.classifier(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "fcg2DqtR5w26"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.1\n",
        "epochs = 100\n",
        "\n",
        "model = myCNN(input_features=1)\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "  epoch_loss = []\n",
        "\n",
        "  for batch_features, batch_labels in traindataloader:\n",
        "\n",
        "    batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
        "\n",
        "    prediction = model(batch_features)\n",
        "\n",
        "    loss = loss_function(prediction, batch_labels)\n",
        "\n",
        "    epoch_loss.append(loss.item())\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "  print(f'epoch {epoch} ---> loss {np.mean(np.array(epoch_loss))}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bc8M_rmY54g3",
        "outputId": "9d0f2b9b-ced3-4424-e789-0fe40ae1c325"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0 ---> loss 0.7823931688070297\n",
            "epoch 1 ---> loss 0.540128882461124\n",
            "epoch 2 ---> loss 0.47762037800418006\n",
            "epoch 3 ---> loss 0.43995882040924494\n",
            "epoch 4 ---> loss 0.41460473120212554\n",
            "epoch 5 ---> loss 0.3935819516248173\n",
            "epoch 6 ---> loss 0.38472540855407716\n",
            "epoch 7 ---> loss 0.3642635241150856\n",
            "epoch 8 ---> loss 0.35435586922698553\n",
            "epoch 9 ---> loss 0.3394855343302091\n",
            "epoch 10 ---> loss 0.336194695631663\n",
            "epoch 11 ---> loss 0.3266560067070855\n",
            "epoch 12 ---> loss 0.3195132307211558\n",
            "epoch 13 ---> loss 0.3144393637776375\n",
            "epoch 14 ---> loss 0.3057967420419057\n",
            "epoch 15 ---> loss 0.29839123795429867\n",
            "epoch 16 ---> loss 0.2916803477538957\n",
            "epoch 17 ---> loss 0.28814259697993594\n",
            "epoch 18 ---> loss 0.285796532250113\n",
            "epoch 19 ---> loss 0.28140907242894175\n",
            "epoch 20 ---> loss 0.277144201911158\n",
            "epoch 21 ---> loss 0.2710143254035049\n",
            "epoch 22 ---> loss 0.26881766453385353\n",
            "epoch 23 ---> loss 0.2612600562142001\n",
            "epoch 24 ---> loss 0.26112108811736107\n",
            "epoch 25 ---> loss 0.2589122547705968\n",
            "epoch 26 ---> loss 0.25667368181877664\n",
            "epoch 27 ---> loss 0.25552407670352195\n",
            "epoch 28 ---> loss 0.24949751989709007\n",
            "epoch 29 ---> loss 0.24887232298652331\n",
            "epoch 30 ---> loss 0.24345144808292388\n",
            "epoch 31 ---> loss 0.2399340203901132\n",
            "epoch 32 ---> loss 0.24040262742174998\n",
            "epoch 33 ---> loss 0.23523591925700504\n",
            "epoch 34 ---> loss 0.2324247384402487\n",
            "epoch 35 ---> loss 0.231362756854958\n",
            "epoch 36 ---> loss 0.22686118538180988\n",
            "epoch 37 ---> loss 0.23144210090239842\n",
            "epoch 38 ---> loss 0.22787417617109088\n",
            "epoch 39 ---> loss 0.2243191679649883\n",
            "epoch 40 ---> loss 0.22386269961794217\n",
            "epoch 41 ---> loss 0.22131366049249968\n",
            "epoch 42 ---> loss 0.2190839950905906\n",
            "epoch 43 ---> loss 0.2174965148170789\n",
            "epoch 44 ---> loss 0.21483119443058968\n",
            "epoch 45 ---> loss 0.2090153492324882\n",
            "epoch 46 ---> loss 0.21213999584317209\n",
            "epoch 47 ---> loss 0.21079730134871272\n",
            "epoch 48 ---> loss 0.20935666708482636\n",
            "epoch 49 ---> loss 0.20893506013684804\n",
            "epoch 50 ---> loss 0.20579458297126824\n",
            "epoch 51 ---> loss 0.20320006989770464\n",
            "epoch 52 ---> loss 0.20598495401442052\n",
            "epoch 53 ---> loss 0.20236170466575357\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "  pred = model(testdataset.features.to(device))\n",
        "  pred = torch.argmax(pred, dim=1)\n",
        "  score = accuracy_score(testdataset.labels.cpu(), pred.cpu())\n",
        "\n",
        "print(score)"
      ],
      "metadata": {
        "id": "qhTWmdj6Dk6T"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}