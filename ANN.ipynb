{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f630239",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933cc1ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-1894780179.py:10: DeprecationWarning: Use dataset_load() instead of load_dataset(). load_dataset() will be removed in a future version.\n",
      "  df = kagglehub.load_dataset(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Colab cache for faster access to the 'fashionmnist' dataset.\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "from kagglehub import KaggleDatasetAdapter\n",
    "\n",
    "file_path = \"fashion-mnist_test.csv\"\n",
    "\n",
    "df = kagglehub.load_dataset(\n",
    "  KaggleDatasetAdapter.PANDAS,\n",
    "  \"zalando-research/fashionmnist\",\n",
    "  file_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b3e0622",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, 1:]\n",
    "y = df.iloc[:, 0]\n",
    "\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X, y, shuffle=True, random_state=42)\n",
    "\n",
    "xtrain = xtrain/255\n",
    "xtest = xtest/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4c60b2ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7bb393f7b5f0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(xtrain.iloc[9, :].values.reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "467ffd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad0580b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class mnistANN(nn.Module):\n",
    "\n",
    "    def __init__(self, num_features):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(num_features, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 10),\n",
    "            # nn.Softmax() no need to write as nn.CrossEntropyLoss will apply softmax and then calculate neg log likelihood loss\n",
    "        )\n",
    "    \n",
    "    def forward(self, features):\n",
    "        return self.network(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "06b0b611",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_tensor = torch.from_numpy(xtrain.values).float()\n",
    "xtest_tensor = torch.from_numpy(xtest.values).float()\n",
    "ytrain_tensor = torch.from_numpy(ytrain.values).float()\n",
    "ytest_tensor = torch.from_numpy(ytest.values).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "58758619",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindataset = CustomDataset(xtrain_tensor, ytrain_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4f98fe8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindataloader = DataLoader(traindataset, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4f10da2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 -> loss 0.12353703379631042\n",
      "epoch 2 -> loss 0.11922573298215866\n",
      "epoch 3 -> loss 0.09419023990631104\n",
      "epoch 4 -> loss 0.09001873433589935\n",
      "epoch 5 -> loss 0.058838989585638046\n",
      "epoch 6 -> loss 0.081086166203022\n",
      "epoch 7 -> loss 0.07443913072347641\n",
      "epoch 8 -> loss 0.07778101414442062\n",
      "epoch 9 -> loss 0.05945557355880737\n",
      "epoch 10 -> loss 0.05488996580243111\n",
      "epoch 11 -> loss 0.048369430005550385\n",
      "epoch 12 -> loss 0.06796130537986755\n",
      "epoch 13 -> loss 0.05737898871302605\n",
      "epoch 14 -> loss 0.049661848694086075\n",
      "epoch 15 -> loss 0.06215205788612366\n",
      "epoch 16 -> loss 0.04853085055947304\n",
      "epoch 17 -> loss 0.055366214364767075\n",
      "epoch 18 -> loss 0.03574371710419655\n",
      "epoch 19 -> loss 0.04127131775021553\n",
      "epoch 20 -> loss 0.05032864585518837\n",
      "epoch 21 -> loss 0.05422135815024376\n",
      "epoch 22 -> loss 0.04647801071405411\n",
      "epoch 23 -> loss 0.05456406995654106\n",
      "epoch 24 -> loss 0.03728592395782471\n",
      "epoch 25 -> loss 0.04801404848694801\n",
      "epoch 26 -> loss 0.051299210637807846\n",
      "epoch 27 -> loss 0.035918667912483215\n",
      "epoch 28 -> loss 0.041027698665857315\n",
      "epoch 29 -> loss 0.0526457354426384\n",
      "epoch 30 -> loss 0.04677494615316391\n",
      "epoch 31 -> loss 0.05353371053934097\n",
      "epoch 32 -> loss 0.02747795544564724\n",
      "epoch 33 -> loss 0.025201993063092232\n",
      "epoch 34 -> loss 0.035870131105184555\n",
      "epoch 35 -> loss 0.027087325230240822\n",
      "epoch 36 -> loss 0.04426845163106918\n",
      "epoch 37 -> loss 0.02836715616285801\n",
      "epoch 38 -> loss 0.03004344552755356\n",
      "epoch 39 -> loss 0.028403665870428085\n",
      "epoch 40 -> loss 0.03483518213033676\n",
      "epoch 41 -> loss 0.009532954543828964\n",
      "epoch 42 -> loss 0.0464317686855793\n",
      "epoch 43 -> loss 0.03547259420156479\n",
      "epoch 44 -> loss 0.016398761421442032\n",
      "epoch 45 -> loss 0.016149232164025307\n",
      "epoch 46 -> loss 0.017882540822029114\n",
      "epoch 47 -> loss 0.01947621814906597\n",
      "epoch 48 -> loss 0.032926950603723526\n",
      "epoch 49 -> loss 0.028090406209230423\n",
      "epoch 50 -> loss 0.035708069801330566\n",
      "epoch 51 -> loss 0.01490766555070877\n",
      "epoch 52 -> loss 0.022335460409522057\n",
      "epoch 53 -> loss 0.02117553912103176\n",
      "epoch 54 -> loss 0.02138563245534897\n",
      "epoch 55 -> loss 0.02708517387509346\n",
      "epoch 56 -> loss 0.022824779152870178\n",
      "epoch 57 -> loss 0.03083471581339836\n",
      "epoch 58 -> loss 0.02362842485308647\n",
      "epoch 59 -> loss 0.020347287878394127\n",
      "epoch 60 -> loss 0.011847352609038353\n",
      "epoch 61 -> loss 0.016042979434132576\n",
      "epoch 62 -> loss 0.03597855567932129\n",
      "epoch 63 -> loss 0.022635111585259438\n",
      "epoch 64 -> loss 0.011657403782010078\n",
      "epoch 65 -> loss 0.017043832689523697\n",
      "epoch 66 -> loss 0.025737307965755463\n",
      "epoch 67 -> loss 0.020389802753925323\n",
      "epoch 68 -> loss 0.01822136528789997\n",
      "epoch 69 -> loss 0.030102431774139404\n",
      "epoch 70 -> loss 0.019569454714655876\n",
      "epoch 71 -> loss 0.01760329119861126\n",
      "epoch 72 -> loss 0.010153397917747498\n",
      "epoch 73 -> loss 0.022769516333937645\n",
      "epoch 74 -> loss 0.013799035921692848\n",
      "epoch 75 -> loss 0.016131538897752762\n",
      "epoch 76 -> loss 0.01682368293404579\n",
      "epoch 77 -> loss 0.012872149236500263\n",
      "epoch 78 -> loss 0.05624007433652878\n",
      "epoch 79 -> loss 0.012280385009944439\n",
      "epoch 80 -> loss 0.007891993038356304\n",
      "epoch 81 -> loss 0.007458616979420185\n",
      "epoch 82 -> loss 0.014722056686878204\n",
      "epoch 83 -> loss 0.020499151200056076\n",
      "epoch 84 -> loss 0.013188494369387627\n",
      "epoch 85 -> loss 0.0114158159121871\n",
      "epoch 86 -> loss 0.016336634755134583\n",
      "epoch 87 -> loss 0.016530420631170273\n",
      "epoch 88 -> loss 0.011783293448388577\n",
      "epoch 89 -> loss 0.016247916966676712\n",
      "epoch 90 -> loss 0.022671956568956375\n",
      "epoch 91 -> loss 0.008180217817425728\n",
      "epoch 92 -> loss 0.009785217233002186\n",
      "epoch 93 -> loss 0.011073283851146698\n",
      "epoch 94 -> loss 0.018088001757860184\n",
      "epoch 95 -> loss 0.013731209561228752\n",
      "epoch 96 -> loss 0.008261953480541706\n",
      "epoch 97 -> loss 0.016430169343948364\n",
      "epoch 98 -> loss 0.012374596670269966\n",
      "epoch 99 -> loss 0.007179479114711285\n",
      "epoch 100 -> loss 0.01124686747789383\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.1\n",
    "epochs = 100\n",
    "\n",
    "model = mnistANN(num_features=xtrain.shape[1])\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for batch_features, batch_labels in traindataloader:\n",
    "\n",
    "        ypred = model(batch_features)\n",
    "\n",
    "        loss = loss_function(ypred, batch_labels.long())\n",
    "\n",
    "        epoch_loss += loss.item() \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f'epoch {epoch+1} -> loss {loss/(xtrain_tensor.shape[1]/100)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c6b520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.86      0.81       235\n",
      "         1.0       0.97      0.97      0.97       236\n",
      "         2.0       0.75      0.76      0.76       254\n",
      "         3.0       0.89      0.88      0.89       242\n",
      "         4.0       0.81      0.80      0.81       251\n",
      "         5.0       0.91      0.94      0.93       250\n",
      "         6.0       0.73      0.64      0.68       257\n",
      "         7.0       0.92      0.90      0.91       258\n",
      "         8.0       0.95      0.96      0.96       253\n",
      "         9.0       0.94      0.92      0.93       264\n",
      "\n",
      "    accuracy                           0.86      2500\n",
      "   macro avg       0.86      0.87      0.86      2500\n",
      "weighted avg       0.86      0.86      0.86      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval() # helpful because certain part of NN, work differently during traing and prediction, like dropouts and batchnormalization\n",
    "\n",
    "with torch.no_grad():\n",
    "    ytest_pred = model(xtest_tensor)\n",
    "    ytest_pred = ytest_pred.argmax(dim=1)\n",
    "\n",
    "print(classification_report(ytest_tensor, ytest_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba1d7dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
